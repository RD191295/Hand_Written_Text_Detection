{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-17T15:06:29.949434Z","iopub.execute_input":"2022-08-17T15:06:29.951806Z","iopub.status.idle":"2022-08-17T15:06:29.966940Z","shell.execute_reply.started":"2022-08-17T15:06:29.951743Z","shell.execute_reply":"2022-08-17T15:06:29.965929Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Extracting dataset\n!tar zxvf ../input/hand-written-text-detection-dataset/words.tgz\nfrom IPython.display import clear_output\nclear_output()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!tar zxvf ../input/hand-written-text-detection-dataset/ascii.tgz","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:06:50.912548Z","iopub.execute_input":"2022-08-17T15:06:50.913632Z","iopub.status.idle":"2022-08-17T15:06:51.994271Z","shell.execute_reply.started":"2022-08-17T15:06:50.913590Z","shell.execute_reply":"2022-08-17T15:06:51.992757Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!head -20 words.txt","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:06:51.999722Z","iopub.execute_input":"2022-08-17T15:06:52.000738Z","iopub.status.idle":"2022-08-17T15:06:53.331210Z","shell.execute_reply.started":"2022-08-17T15:06:52.000694Z","shell.execute_reply":"2022-08-17T15:06:53.329931Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Import Libraries\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport cv2 \nfrom tensorflow import keras\nimport os\nfrom tensorflow.keras.layers.experimental.preprocessing import StringLookup\nimport tensorflow as tf\n\nnp.random.seed(42)\ntf.random.set_seed(42)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:06:53.333002Z","iopub.execute_input":"2022-08-17T15:06:53.339435Z","iopub.status.idle":"2022-08-17T15:06:56.117162Z","shell.execute_reply.started":"2022-08-17T15:06:53.339380Z","shell.execute_reply":"2022-08-17T15:06:56.116174Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"words_list = []\n\nwords = open(\"words.txt\",\"r\").readlines()\n\nfor line in words :\n   if line[0] == \"#\" :\n     continue\n   if line.split(\" \")[1] != \"err\":\n        words_list.append(line)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:06:56.118623Z","iopub.execute_input":"2022-08-17T15:06:56.119922Z","iopub.status.idle":"2022-08-17T15:06:56.204892Z","shell.execute_reply.started":"2022-08-17T15:06:56.119882Z","shell.execute_reply":"2022-08-17T15:06:56.203907Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# check length of words list\nlen(words_list)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:06:56.206291Z","iopub.execute_input":"2022-08-17T15:06:56.206881Z","iopub.status.idle":"2022-08-17T15:06:56.215547Z","shell.execute_reply.started":"2022-08-17T15:06:56.206843Z","shell.execute_reply":"2022-08-17T15:06:56.214475Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# shuffling words\nnp.random.shuffle(words_list)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:06:56.217086Z","iopub.execute_input":"2022-08-17T15:06:56.217766Z","iopub.status.idle":"2022-08-17T15:06:56.232571Z","shell.execute_reply.started":"2022-08-17T15:06:56.217731Z","shell.execute_reply":"2022-08-17T15:06:56.231531Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# spliting dataset in train,test and validation in 90:5:5 ratio\n\nsplit_index = int(0.9*len(words_list))\n\ntrain_samples = words_list[:split_index]\ntest_samples = words_list[split_index:]\n\nval_split_idx = int(0.5*len(test_samples))\n\nval_samples = test_samples[:val_split_idx]\ntest_samples = test_samples[val_split_idx:]\n\n\n# size of train ,test and validation\nprint('Total Training Samples:' + str(len(train_samples)))\nprint('Total Test Samples:' + str(len(test_samples)))\nprint('Total Validation Samples:' + str(len(val_samples)))","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:06:56.235610Z","iopub.execute_input":"2022-08-17T15:06:56.236625Z","iopub.status.idle":"2022-08-17T15:06:56.246471Z","shell.execute_reply.started":"2022-08-17T15:06:56.236582Z","shell.execute_reply":"2022-08-17T15:06:56.245425Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Data Pipeline (Image Paths)","metadata":{}},{"cell_type":"code","source":"base_path = os.getcwd()\ndef get_image_path_labels(samples):\n  paths = []\n  corrected_samples = []\n\n  for(i,file_line) in enumerate(samples):\n    line_split = file_line.strip()\n    line_split = line_split.split(\" \")\n    \n    # Each line split will have this format for the corresponding image:\n    # part1/part1-part2/part1-part2-part3.png\n    image_name = line_split[0]\n    part_1 = image_name.split(\"-\")[0]\n    part_2 = image_name.split(\"-\")[1]\n    img_path = os.path.join(base_path ,part_1,part_1 + \"-\" + part_2,image_name+\".png\")\n\n    if os.path.getsize(img_path):\n      paths.append(img_path)\n      corrected_samples.append(file_line.split(\"\\n\")[0])\n  \n  return paths,corrected_samples\n\ntrain_img_paths, train_labels = get_image_path_labels(train_samples)\ntest_img_paths, test_labels = get_image_path_labels(test_samples)\nval_img_paths, val_labels = get_image_path_labels(val_samples)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:06:56.248381Z","iopub.execute_input":"2022-08-17T15:06:56.249166Z","iopub.status.idle":"2022-08-17T15:06:57.067622Z","shell.execute_reply.started":"2022-08-17T15:06:56.249129Z","shell.execute_reply":"2022-08-17T15:06:57.066579Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Ground Truth labels ....\ntrain_labels_cleaned = []\ncharacters = set()\nmax_length = 0\n\nfor label in train_labels:\n  label = label.split(\" \")[-1].strip()\n  for char in label:\n    characters.add(char)\n  max_length = max(max_length, len(label))\n  train_labels_cleaned.append(label)\ncharacters = sorted(list(characters))\n\n\n# Maximum Length\nprint(\"Maximum Length:\", max_length)\nprint(\"vocabulary size:\",len(characters))\n\ntrain_labels_cleaned[:10]","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:06:57.070462Z","iopub.execute_input":"2022-08-17T15:06:57.070887Z","iopub.status.idle":"2022-08-17T15:06:57.220342Z","shell.execute_reply.started":"2022-08-17T15:06:57.070846Z","shell.execute_reply":"2022-08-17T15:06:57.219346Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# validation and test dataset clean\n\ndef clean_labels(labels):\n  cleaned_labels = []\n  for label in labels:\n    label = label.split(\" \")[-1].strip()\n    cleaned_labels.append(label)\n  return cleaned_labels\n\nvalidation_labels_cleaned = clean_labels(val_labels)\ntest_labels_cleaned = clean_labels(test_labels)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:06:57.221971Z","iopub.execute_input":"2022-08-17T15:06:57.222618Z","iopub.status.idle":"2022-08-17T15:06:57.443617Z","shell.execute_reply.started":"2022-08-17T15:06:57.222578Z","shell.execute_reply":"2022-08-17T15:06:57.442014Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\n\n# mapping char to numerica\nchar_to_num = StringLookup(vocabulary=list(characters), mask_token = None)\n\n# Mapping numeric to orignal characters\nnum_to_char = StringLookup(vocabulary= char_to_num.get_vocabulary(),mask_token = None, invert=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:06:57.450822Z","iopub.execute_input":"2022-08-17T15:06:57.451887Z","iopub.status.idle":"2022-08-17T15:06:58.585733Z","shell.execute_reply.started":"2022-08-17T15:06:57.451847Z","shell.execute_reply":"2022-08-17T15:06:58.584736Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# image pre processing (resizing)\ndef img_resize(image,img_size):\n  w,h = img_size\n  image = tf.image.resize(image,size = (h,w), preserve_aspect_ratio = True)\n\n  # Check tha amount of padding needed to be done.\n  pad_height = h - tf.shape(image)[0]\n  pad_width = w - tf.shape(image)[1]\n\n   # Only necessary if you want to do same amount of padding on both sides.\n  if pad_height % 2 != 0:\n      height = pad_height // 2\n      pad_height_top = height + 1\n      pad_height_bottom = height\n  else:\n      pad_height_top = pad_height_bottom = pad_height // 2\n\n  if pad_width % 2 != 0:\n      width = pad_width // 2\n      pad_width_left = width + 1\n      pad_width_right = width\n  else:\n      pad_width_left = pad_width_right = pad_width // 2\n\n  image = tf.pad(\n      image,\n      paddings=[\n          [pad_height_top, pad_height_bottom],\n          [pad_width_left, pad_width_right],\n          [0, 0],\n      ],\n  )\n\n  image = tf.transpose(image, perm=[1, 0, 2])\n  image = tf.image.flip_left_right(image)\n  return image","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:06:58.587729Z","iopub.execute_input":"2022-08-17T15:06:58.588808Z","iopub.status.idle":"2022-08-17T15:06:58.597562Z","shell.execute_reply.started":"2022-08-17T15:06:58.588768Z","shell.execute_reply":"2022-08-17T15:06:58.596576Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\npadding_token = 99\nimage_width = 128\nimage_height = 32\n\n\ndef process_img(image_path, img_size = (image_width,image_height)):\n  image = tf.io.read_file(image_path)\n  image = tf.image.decode_png(image,1)\n  image = img_resize(image,img_size)\n  image = tf.cast(image,tf.float32)/255.0\n  return image\n\ndef vectorize_label(label):\n  label = char_to_num(tf.strings.unicode_split(label, input_encoding = \"UTF-8\"))\n  length = tf.shape(label)[0]\n  pad_amount = max_length - length\n  label = tf.pad(label,paddings = [[0,pad_amount]],constant_values = padding_token)\n  return label\n\ndef process_img_labels(image_path,label):\n  image = process_img(image_path)\n  label = vectorize_label(label)\n  return {\"image\": image, \"label\": label}\n\ndef prepare_dataset(image_path,label):\n  dataset = tf.data.Dataset.from_tensor_slices((image_path,label)).map(process_img_labels, num_parallel_calls=AUTOTUNE)\n\n  return dataset.batch(batch_size).cache().prefetch(AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:06:58.599031Z","iopub.execute_input":"2022-08-17T15:06:58.600160Z","iopub.status.idle":"2022-08-17T15:06:59.846697Z","shell.execute_reply.started":"2022-08-17T15:06:58.600101Z","shell.execute_reply":"2022-08-17T15:06:59.845316Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# prepare dataset\ntrain_dataset = prepare_dataset(train_img_paths, train_labels_cleaned)\nval_dataset = prepare_dataset(val_img_paths, validation_labels_cleaned)\ntest_dataset = prepare_dataset(test_img_paths, test_labels_cleaned)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:06:59.848341Z","iopub.execute_input":"2022-08-17T15:06:59.848735Z","iopub.status.idle":"2022-08-17T15:07:01.156325Z","shell.execute_reply.started":"2022-08-17T15:06:59.848675Z","shell.execute_reply":"2022-08-17T15:07:01.155269Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# visualizing train dataset\nimport matplotlib.pyplot as plt\nfor data in train_dataset.take(1):\n    images, labels = data[\"image\"], data[\"label\"]\n\n    _, ax = plt.subplots(4, 4, figsize=(15, 8))\n\n    for i in range(16):\n        img = images[i]\n        img = tf.image.flip_left_right(img)\n        img = tf.transpose(img, perm=[1, 0, 2])\n        img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n        img = img[:, :, 0]\n\n        # Gather indices where label!= padding_token.\n        label = labels[i]\n        indices = tf.gather(label, tf.where(tf.math.not_equal(label, padding_token)))\n        # Convert to string.\n        label = tf.strings.reduce_join(num_to_char(indices))\n        label = label.numpy().decode(\"utf-8\")\n\n        ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n        ax[i // 4, i % 4].set_title(label)\n        ax[i // 4, i % 4].axis(\"off\")\n\n\nplt.show()\nfrom IPython.display import clear_output\nclear_output()","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:07:01.158052Z","iopub.execute_input":"2022-08-17T15:07:01.158489Z","iopub.status.idle":"2022-08-17T15:07:02.330971Z","shell.execute_reply.started":"2022-08-17T15:07:01.158425Z","shell.execute_reply":"2022-08-17T15:07:02.329957Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Let us create Model\n# ----- CTC loss ---------------\n@tf.keras.utils.register_keras_serializable()\nclass CTCLayer(keras.layers.Layer):\n  def __init__(self,name = None ,**kwargs):\n    self.loss_fun = keras.backend.ctc_batch_cost\n    super(CTCLayer, self).__init__(**kwargs)\n  \n  def get_config(self):\n    config = super().get_config()\n    return config\n\n  def call(self, y_true , y_pred):\n    batch_len = tf.cast(tf.shape(y_true)[0],dtype = \"int64\")\n\n    input_length = tf.cast(tf.shape(y_pred)[1],dtype = \"int64\")\n    label_length = tf.cast(tf.shape(y_true)[1],dtype = \"int64\")\n\n    input_length = input_length * tf.ones(shape = (batch_len , 1) , dtype = \"int64\") \n    label_length = label_length * tf.ones(shape = (batch_len , 1) , dtype = \"int64\")\n\n    loss = self.loss_fun(y_true, y_pred, input_length, label_length )\n    self.add_loss(loss)\n\n    return y_pred\n\ndef build_model():\n\n  # Input layer\n  input_img = keras.Input(shape = (image_width, image_height, 1), name=\"image\")\n  labels = keras.layers.Input(name = \"label\",shape = (None,))\n\n  # Conv2D layer 1\n  X = keras.layers.Conv2D(\n      32,\n      (3,3),\n      activation = \"relu\",\n      kernel_initializer = \"he_normal\",\n      padding = \"same\",\n      name = \"conv1\"\n  )(input_img)\n\n  X = keras.layers.MaxPool2D(\n      pool_size = (2,2),\n      name = \"pool1\"\n  )(X)\n\n  # COnv2D layer 2\n\n  X = keras.layers.Conv2D(\n      64,\n      (3,3),\n      activation = \"relu\",\n      kernel_initializer = \"he_normal\",\n      padding = \"same\",\n      name = \"conv2\"\n  )(X)\n\n  X = keras.layers.MaxPool2D(\n      pool_size = (2,2),\n      name = \"pool2\"\n  )(X)\n\n  # we have used 2 max pool with pool size and strides = 2\n  # hence downsampled feature size are 4x smaller... the number\n  # of filters in last layers are 64. reshape input accordingly\n  # before passing to RNN layers\n\n  new_shape = ((image_width // 4), (image_height // 4) * 64)\n  X = keras.layers.Reshape(target_shape = new_shape, name = \"reshape\")(X)\n\n  # Dense Layer --- 1\n  X = keras.layers.Dense(64,activation = \"relu\", name = \"Dense1\")(X)\n  X = keras.layers.Dropout(0.2)(X)\n\n  # RNN --- bi direction LSTM -1\n  X = keras.layers.Bidirectional(\n      keras.layers.LSTM(128,return_sequences= True,dropout=0.25)\n  )(X)\n  \n  # RNN --- bi direction LSTM -2\n  X = keras.layers.Bidirectional(\n      keras.layers.LSTM(128,return_sequences= True,dropout=0.25)\n  )(X)\n\n  # Dense Layer ---2\n  X = keras.layers.Dense(\n      len(char_to_num.get_vocabulary())+2,\n      activation = \"softmax\",\n      name = \"Dense2\"\n  )(X)\n\n  # CTC layer \n  output = CTCLayer(name = \"ctc_loss\")(labels,X)\n\n  # define model\n  model = keras.models.Model(\n      inputs = [input_img, labels],\n      outputs = output,\n      name = \"Hand_Written_Text_Recognizer\"\n  )\n\n  # Optimizer ---we will  use adam\n  opt = keras.optimizers.Adam()\n\n  # compile model \n  model.compile(optimizer = opt)\n\n  return model\n\n\n# call model function\nmodel = build_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:07:02.332066Z","iopub.execute_input":"2022-08-17T15:07:02.332400Z","iopub.status.idle":"2022-08-17T15:07:03.416613Z","shell.execute_reply.started":"2022-08-17T15:07:02.332366Z","shell.execute_reply":"2022-08-17T15:07:03.415539Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Evaluation metric : Edit Method is widely used evalution metric for OCR based application\n# this metric we will use for callback in model training\n\n\nvalidation_images = []\nvalidation_labels = []\n\nfor batch in val_dataset:\n  validation_images.append(batch[\"image\"])\n  validation_labels.append(batch[\"label\"])\nfrom IPython.display import clear_output\nclear_output()","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:34:02.944079Z","iopub.execute_input":"2022-08-17T15:34:02.944402Z","iopub.status.idle":"2022-08-17T15:34:02.993368Z","shell.execute_reply.started":"2022-08-17T15:34:02.944372Z","shell.execute_reply":"2022-08-17T15:34:02.992278Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def calculate_edit_distance(labels, predictions):\n    # Get a single batch and convert its labels to sparse tensors.\n    saprse_labels = tf.cast(tf.sparse.from_dense(labels), dtype=tf.int64)\n\n    # Make predictions and convert them to sparse tensors.\n    input_len = np.ones(predictions.shape[0]) * predictions.shape[1]\n    predictions_decoded = keras.backend.ctc_decode(\n        predictions, input_length=input_len, greedy=True\n    )[0][0][:, :max_length]\n    sparse_predictions = tf.cast(\n        tf.sparse.from_dense(predictions_decoded), dtype=tf.int64\n    )\n\n    # Compute individual edit distances and average them out.\n    edit_distances = tf.edit_distance(\n        sparse_predictions, saprse_labels, normalize=False\n    )\n    return tf.reduce_mean(edit_distances)\n\n\nclass EditDistanceCallback(keras.callbacks.Callback):\n    def __init__(self, pred_model):\n        super().__init__()\n        self.prediction_model = pred_model\n\n    def on_epoch_end(self, epoch, logs=None):\n        edit_distances = []\n\n        for i in range(len(validation_images)):\n            labels = validation_labels[i]\n            predictions = self.prediction_model.predict(validation_images[i])\n            edit_distances.append(calculate_edit_distance(labels, predictions).numpy())\n\n        print(\n            f\" Mean edit distance for epoch {epoch + 1}: {np.mean(edit_distances):.4f}\"\n        )","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:07:06.387200Z","iopub.execute_input":"2022-08-17T15:07:06.387850Z","iopub.status.idle":"2022-08-17T15:07:06.397439Z","shell.execute_reply.started":"2022-08-17T15:07:06.387810Z","shell.execute_reply":"2022-08-17T15:07:06.396516Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Training\nNow we are ready to kick off model training.","metadata":{}},{"cell_type":"code","source":"epochs = 20  # To get good results this should be at least 50.\n\nmodel = build_model()\nprediction_model = keras.models.Model(\n    model.get_layer(name=\"image\").input, model.get_layer(name=\"Dense2\").output\n)\nedit_distance_callback = EditDistanceCallback(prediction_model)\n\n# Train the model.\nhistory = model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=epochs,\n    batch_size = 64,\n    callbacks=[edit_distance_callback],\n)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:07:06.399169Z","iopub.execute_input":"2022-08-17T15:07:06.399844Z","iopub.status.idle":"2022-08-17T15:34:00.644043Z","shell.execute_reply.started":"2022-08-17T15:07:06.399804Z","shell.execute_reply":"2022-08-17T15:34:00.642965Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model.save(\"./Hand_Written_text_detection.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:34:00.645996Z","iopub.execute_input":"2022-08-17T15:34:00.646401Z","iopub.status.idle":"2022-08-17T15:34:00.727521Z","shell.execute_reply.started":"2022-08-17T15:34:00.646365Z","shell.execute_reply":"2022-08-17T15:34:00.726527Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"new_model = tf.keras.models.load_model('./Hand_Written_text_detection.h5')","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-08-17T15:34:00.728988Z","iopub.execute_input":"2022-08-17T15:34:00.729362Z","iopub.status.idle":"2022-08-17T15:34:01.773306Z","shell.execute_reply.started":"2022-08-17T15:34:00.729325Z","shell.execute_reply":"2022-08-17T15:34:01.772236Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef decode_batch_pred(pred):\n  input_len = np.ones(pred.shape[0])*pred.shape[1]\n  results = tf.keras.backend.ctc_decode(\n      pred , input_length = input_len , greedy = True \n  )[0][0][:,:max_length]\n  output_text = []\n  for res in results:\n    res = tf.gather(res , tf.where(tf.math.not_equal(res, -1)))\n    res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n    output_text.append(res)\n  return output_text\n\nfor batch in test_dataset.take(1):\n  batch_images = batch[\"image\"]\n  batch_label =batch[\"label\"]\n  _,ax = plt.subplots(4, 4, figsize=(15,10))\n\n  preds = prediction_model.predict(batch_images)\n  pred_texts = decode_batch_pred(preds)\n\n  for i in range(16):\n    image = batch_images[i]\n    image = tf.image.flip_left_right(image)\n    image = tf.transpose(image, perm=[1, 0, 2])\n    image = (image * 255.0).numpy().clip(0, 255).astype(np.uint8)\n    image = image[:,:,0]\n\n    title = f\"Prediction: {pred_texts[i]}\"\n    ax[i // 4, i % 4].imshow(image, cmap=\"gray\")\n    ax[i // 4, i % 4].set_title(title)\n    ax[i // 4, i % 4].axis(\"off\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:34:01.774963Z","iopub.execute_input":"2022-08-17T15:34:01.775350Z","iopub.status.idle":"2022-08-17T15:34:02.940256Z","shell.execute_reply.started":"2022-08-17T15:34:01.775313Z","shell.execute_reply":"2022-08-17T15:34:02.939182Z"},"trusted":true},"execution_count":24,"outputs":[]}]}